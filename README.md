# LungNoduleDetctionNGCNN
Visual problem inspections of the CT images are prone to error, as it is more complex to distinguish lung nodules from the background tissues, which are subjective to intra and interobserver variability. We designed and developed a state-of-the-art predictive deep learning model for medical imaging to detect cancerous nodules using Convolutional Neural Networks [CNN] architecture with TensorFlow. 
# Pre-processing
Pre-processing the medical image is dominant as it affects the prediction results. Gaussian noise is most recurrent in the medical scan as it occurs in the analog circuit, which is a fundamental operation in CT scans. Since Gaussian noise affects every pixel, it reduces the quality of the overall image. This leads to poor interpretation and false diagnosis by the radiologists. Hence, we proposed NG-CNN for a more accurate prediction of the lung image. With this advantage, the Non-Gaussian model is utilised for real-time prediction for enhancing modelling behaviour. This work concentrates on recognising the lung nodule malignancy by integrating the non-Gaussian process with convolutional neural networks to extract the features without using any time-consuming processing steps. Here, the geometric features are derived from the lung using CT input image datasets using an efficient deep learning process. This investigation integrates the Non-Gaussian process for eliminating the occurrence of fault while performing classification and stacked Adaptive Histogram Equalization based ROI segmentation as a pre-processing step. EAHE has been presented to enhance the quality of CT images to extract the geometric feature with a clear view of minute parts of lung nodules. Followed by this is the deep learning-based NG-CNN for classification. After performing cross-validation of extracted features, lung nodule classification and fault identification were performed using the proposed NG-CNN method to get a test classification output of benign/malignant lung nodule. The anticipated methodology was tested on LUNA 2016 dataset and outperformed the most exceptional accuracy of 96.97%, precision of 99.75%, recall of 98.16% and F-measure of 97.94%
# Segmentation
Construct a binary mask based on the dimensions given in the file by labelling threshold points that belong to the component. Thresholding the tissue to -340 HU and dilating eliminates the edges and parts other than lungs region. Usually, lungs show more contrast than the nearby tissue.Perform morphological operation over a binary mask using monotonically increasing function which fills the structures. HU values that range from -1000 to 400 are eliminated because those values indicate the bones with various density. With monotonically increasing function, changes in ROI measurements are observed with higher derivatives. It uses error measurements that can be both positive and negative. However, we interpret the regions for noise and measure them. After re-labelling generated connected components, remove components whose size is relatively small (smaller than the size of the largest one).
# Classification
The proposed NG-CNN model utilises three convolutional layers along with Rectified Linear Unit, max-pooling layers with pre-processing noise removal are given in figure 5. The first layer, which is the convolutional layer maps our lung image dataset with multi-dimensional filters which give us the first layer output. This intermediate output is fed as an input to the next layer. There are different pooling layers: max pooling, average pooling, sum pooling, and the like. We chose max-pooling as it gives the maximum value in all the patches from the previous layer. We deploy Rectified Linear Unit as an activation layer for our proposed NG-CNN, which solves the adverse value problems and to avoid computation expense f(x) = max(x,0). For our lung nodule dataset, the output can have many classification stages. (i) The patient has no nodule if the nodule size is less than 1.5 mm (ii) The patient has treatable nodule if the size of the nodule falls within 1.5 mm to 3 mm (iii) The patient has severe nodule if the nodule size is more significant than 3mm. However, there are still many stages in nodules, as most of them are treatable. In our proposed methodology, if the patient has nodule of size more than 1.25 mm thickness, then the output of the algorithm is positive, stating immediate attention. The output is negative if the nodule size is less than 1.25 mm, resulting in binary classifications. Finally, the softmax layer is applied to deal with the classification process, and the function is used to categorise the probability distribution. Hence the values are activated from 0 to 1, and the category with the highest probability is considered as output. We resize the pixel size to 256*256*3 without padding to reduce the computational complexity. We used 32 kernels with the size of 5*5. In the max-pooling layer, the pixel size of the lung scan is 128*128*32 and a sampling layer used for minimising pixel values. This reduction is based on trained samples from which ROI is detected. We set the batch size to 160 with a training dataset of 25600. 5*5 and 3*3 filters for first and second convolutional layers are defined. 2*2 for max-pooling operation is applied in our algorithm with a random stride of value 1. In the second layer of de-noising, pixel size is 128*128*64 and 64*64*128 during max pooling for the second time. Finally, in the third convolutional layer, lung image is 64*64*128 and max pooled to 32*32. After each convolutional layer, noise removal is applied in the iteration for visual noise elimination. The softmax layer of our methodology is 2*1. Each patient has several slices according to a scan taken at the hospital. Slices per patient are put into a particular number of chunks. The input batch size is 160 and 40 iterations per epoch which are used to train samples with learning rate 10-2 and gradually decayed over the process. The iterations are set to 10000 with 250 epochs and four-fold cross-validation. The accuracy percentage is evaluated based on several epochs. After cross-validation, the results are averaged by fine-tuning the parameters.
